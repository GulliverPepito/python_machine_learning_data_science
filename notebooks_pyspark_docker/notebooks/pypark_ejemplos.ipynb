{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fb12d547e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import  SparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local[*]\n"
     ]
    }
   ],
   "source": [
    "print(sc.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'spark.driver.host', u'172.18.0.2'),\n",
       " (u'spark.driver.port', u'40277'),\n",
       " (u'spark.sql.catalogImplementation', u'hive'),\n",
       " (u'spark.rdd.compress', u'True'),\n",
       " (u'spark.serializer.objectStreamReset', u'100'),\n",
       " (u'spark.master', u'local[*]'),\n",
       " (u'spark.executor.id', u'driver'),\n",
       " (u'spark.submit.deployMode', u'client'),\n",
       " (u'spark.app.id', u'local-1497109223524'),\n",
       " (u'spark.app.name', u'PySparkShell'),\n",
       " (u'hive.metastore.warehouse.dir', u'file:/notebook/spark-warehouse')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:475"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = range(10)\n",
    "numbers_rdd = sc.parallelize(numbers)\n",
    "\n",
    "numbers_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cuadrado(x):\n",
    "    return x**2\n",
    "\n",
    "numbers_rdd.map(cuadrado).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_rdd.map(lambda x: x**2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###sumatorio de los elementos de un RDD\n",
    "numbers_rdd.map(lambda x: x**2).reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##equivalente al anterior\n",
    "numbers_rdd.map(lambda x: x**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par/impar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('par', 0),\n",
       " ('impar', 1),\n",
       " ('par', 2),\n",
       " ('impar', 3),\n",
       " ('par', 4),\n",
       " ('impar', 5),\n",
       " ('par', 6),\n",
       " ('impar', 7),\n",
       " ('par', 8),\n",
       " ('impar', 9)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def par_impar(x):\n",
    "    return \"par\" if x%2==0 else \"impar\"\n",
    "        \n",
    "    \n",
    "numbers_rdd.map(lambda x: (par_impar(x), x) ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('par', 20), ('impar', 25)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_rdd.map(lambda x: (par_impar(x), x) ).reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeros primos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isprime(n):\n",
    "    \"\"\"\n",
    "    comprueba si es número primo\n",
    "    \"\"\"\n",
    "    # make sure n is a positive integer\n",
    "    n = abs(int(n))\n",
    "    # 0 and 1 are not primes\n",
    "    if n < 2:\n",
    "        return False\n",
    "    # 2 is the only even prime number\n",
    "    if n == 2:\n",
    "        return True\n",
    "    # all other even numbers are not primes\n",
    "    if not n & 1:\n",
    "        return False\n",
    "    # range starts with 3 and only needs to go up the square root of n\n",
    "    # for all odd numbers\n",
    "    for x in range(3, int(n**0.5)+1, 2):\n",
    "        if n % x == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un RDD qe representa una colección de números del 0 al 100\n",
    "nums = sc.parallelize(xrange(100))\n",
    "\n",
    "# Obtener de esa colección de números cuáles son primos\n",
    "print(nums.filter(isprime).count())\n",
    "filter(isprime, xrange(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar catacteres,palabras y lineas de un fichero de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'palabras': 206, 'caracteres': 1356, 'lineas': 4}\n"
     ]
    }
   ],
   "source": [
    "def file_count(line):\n",
    "    return [(\"caracteres\", len(line)), \\\n",
    "            (\"palabras\", len(line.split())), \\\n",
    "            (\"lineas\", 1)]\n",
    "\n",
    "print (sc.textFile(\"about_spark.txt\")\n",
    " .flatMap(file_count)\n",
    " .reduceByKey(lambda a,b: a+b)\n",
    " .collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, u'the')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "print (sc.textFile(\"about_spark.txt\")\n",
    " .flatMap(lambda line: WORD_RE.findall(line))\n",
    " .map(lambda word: (word.lower(), 1))\n",
    " .reduceByKey(lambda a,b: a+b)\n",
    " .map(lambda (k,v): (v,k))\n",
    " .takeOrdered(1, key = lambda x: -x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'the', 9)]\n"
     ]
    }
   ],
   "source": [
    "print (sc.textFile(\"about_spark.txt\")\n",
    " .flatMap(lambda line: [(word.lower(), 1) for word in WORD_RE.findall(line)])\n",
    " .reduceByKey(lambda a,b: a+b)\n",
    " .takeOrdered(1, key = lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras más frecuentes\n",
    "#### Obtener la frecuencia de cada palabra en un fichero de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'and', 8), (u'side,', 2), (u'closely', 1), (u'generality', 1), (u'sup\\u2010', 1), (u'streaming.', 1), (u'is', 7), (u'built-in', 1), (u'as', 1), (u'including', 3)]\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Crear el RDD a partir del fichero de texto\n",
    "text = sc.textFile(\"about_spark.txt\") \n",
    "\n",
    "# Aplicar transformacones sobre el RDD\n",
    "wc   = text.flatMap(tokenize)\n",
    "wc   = wc.map(lambda x: (x,1)).reduceByKey(add)\n",
    "\n",
    "#Obtener las 10 palabras más frecuentes\n",
    "print(wc.take(10))\n",
    "\n",
    "#guardar los resulados en un fichero de salida\n",
    "wc.saveAsTextFile(\"output_file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
